# # ...existing code...
# import streamlit as st
# import torch
# import timm
# from PIL import Image
# from torchvision import transforms
# import torch.nn.functional as F

# # =============================
# # âš™ï¸ Cáº¥u hÃ¬nh ban Ä‘áº§u
# # =============================
# st.set_page_config(page_title="Image Similarity with DINOv3", layout="wide")
# st.title("ğŸ§  So sÃ¡nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a hai áº£nh (DINOv3)")

# device = "cuda" if torch.cuda.is_available() else "cpu"
# st.write(f"**Thiáº¿t bá»‹ sá»­ dá»¥ng:** {device}")
# @st.cache_resource
# def load_model():
#     model_name="vit_huge_plus_patch16_dinov3"
#     # model_name = "vit_large_patch14_dinov3.lvd142m"
#     st.info(f"Äang táº£i mÃ´ hÃ¬nh {model_name}...")
#     model = timm.create_model(model_name, pretrained=True)
#     model.eval()
#     model.to(device)
#     return model

# model = load_model()

# # =============================
# # ğŸ§© HÃ m tiá»n xá»­ lÃ½ vÃ  láº¥y embedding
# # =============================
# transform = transforms.Compose([
#     transforms.Resize((256, 256)),  # Ä‘áº£m báº£o chia háº¿t cho 16
#     transforms.ToTensor(),
#     transforms.Normalize(
#         mean=(0.5, 0.5, 0.5),
#         std=(0.5, 0.5, 0.5)
#     )
# ])

# def get_embedding(img: Image.Image):
#     x = transform(img).unsqueeze(0).to(device)
#     with torch.no_grad():
#         feats = model.forward_features(x)
#     emb = feats.mean(dim=1).squeeze()  # (C,)
#     return emb.cpu()

# # =============================
# # ğŸ–¼ï¸ Giao diá»‡n upload áº£nh
# # =============================
# col1, col2 = st.columns(2)
# with col1:
#     img1_file = st.file_uploader("ğŸ“‚ áº¢nh thá»© nháº¥t", type=["jpg", "jpeg", "png"])
# with col2:
#     img2_file = st.file_uploader("ğŸ“‚ áº¢nh thá»© hai", type=["jpg", "jpeg", "png"])

# # =============================
# # ğŸ” Xá»­ lÃ½ & hiá»ƒn thá»‹ káº¿t quáº£
# # =============================
# if img1_file and img2_file:
#     img1 = Image.open(img1_file).convert("RGB")
#     img2 = Image.open(img2_file).convert("RGB")

#     col1.image(img1, caption="áº¢nh 1", width='stretch')
#     col2.image(img2, caption="áº¢nh 2", width='stretch')

#     with st.spinner("Äang tÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng..."):
#         emb1 = get_embedding(img1)
#         emb2 = get_embedding(img2)
#         similarity = F.cosine_similarity(emb1, emb2, dim=0).item()

#     st.success(f"ğŸ”¹ **Äá»™ tÆ°Æ¡ng Ä‘á»“ng (Cosine Similarity): {similarity:.4f}**")

#     if similarity > 0.85:
#         st.markdown("âœ… Hai áº£nh **ráº¥t giá»‘ng nhau**")
#     elif similarity > 0.5:
#         st.markdown("ğŸŸ¨ Hai áº£nh **cÃ³ nÃ©t tÆ°Æ¡ng Ä‘á»“ng**")
#     else:
#         st.markdown("âŒ Hai áº£nh **khÃ¡c nhau rÃµ rá»‡t**")

# else:

#     st.info("ğŸ‘† HÃ£y táº£i lÃªn hai áº£nh Ä‘á»ƒ so sÃ¡nh.")



import streamlit as st
import base64
from openai import OpenAI

# DeepInfra OpenAI client
client = OpenAI(
    api_key="XDE02cttBlH48cdGoArXCTNRNPWoMlnt",
    base_url="https://api.deepinfra.com/v1/openai",
)

st.title("DeepInfra OCR-1B - Extract Markdown Information")

uploaded_file = st.file_uploader("Upload image", type=["png", "jpg", "jpeg"])

if uploaded_file:
    st.image(uploaded_file, caption="Uploaded Image", use_container_width=True)

    # Convert image â†’ base64
    img_bytes = uploaded_file.read()
    img_b64 = base64.b64encode(img_bytes).decode("utf-8")

    if st.button("ğŸ” Extract Markdown Info"):
        with st.spinner("Processing..."):

            response = client.chat.completions.create(
                model="hoangngochongo3/OCR-3B",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Chuyá»ƒn sang dáº¡ng text markdown vá»›i cÃ¡c pháº§n tiÃªu Ä‘á», danh sÃ¡ch, báº£ng vÃ  Ä‘oáº¡n vÄƒn báº£n tá»« hÃ¬nh áº£nh Ä‘Æ°á»£c cung cáº¥p bÃªn dÆ°á»›i."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{img_b64}"
                                }
                            }
                        ]
                    }
                ]
            )

            extracted_markdown = response.choices[0].message.content

        st.subheader("ğŸ“„ Extracted Markdown:")
        st.markdown(extracted_markdown)
#--trust_remote_code --tokenizer-mode=auto
